"""
–≠–¢–ê–ü 5: Feature Engineering
"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from pathlib import Path
import pickle

# –ü—É—Ç–∏
PROJECT_ROOT = Path(__file__).parent.parent.parent
DATA_DIR = PROJECT_ROOT / 'data' / 'raw'
PROCESSED_DIR = PROJECT_ROOT / 'data' / 'processed'
RESULTS_DIR = PROJECT_ROOT / 'results'

print("=" * 70)
print("–≠–¢–ê–ü 5: Feature Engineering")
print("=" * 70)


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —ç—Ç–∞–ø–∞ 5"""
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    df_train = pd.read_csv(DATA_DIR / 'train.csv')
    df_test = pd.read_csv(DATA_DIR / 'test.csv')
    
    print(f"\nüìä Train: {df_train.shape[0]:,} —Å—Ç—Ä–æ–∫, {df_train.shape[1]} —Å—Ç–æ–ª–±—Ü–æ–≤")
    print(f"üìä Test:  {df_test.shape[0]:,} —Å—Ç—Ä–æ–∫, {df_test.shape[1]} —Å—Ç–æ–ª–±—Ü–æ–≤")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º id –¥–ª—è test (–Ω—É–∂–µ–Ω –¥–ª—è submission)
    test_ids = df_test['id'].copy()
    
    # 1. –£–î–ê–õ–ï–ù–ò–ï –ù–ï–ù–£–ñ–ù–´–• –ü–†–ò–ó–ù–ê–ö–û–í
    print("\n" + "=" * 70)
    print(" 1. –£–î–ê–õ–ï–ù–ò–ï –ù–ï–ù–£–ñ–ù–´–• –ü–†–ò–ó–ù–ê–ö–û–í")
    print("=" * 70)
    
    cols_to_drop = ['id', 'CustomerId', 'Surname']
    
    print(f"\n–£–¥–∞–ª—è–µ–º: {', '.join(cols_to_drop)}")
    print("–ü—Ä–∏—á–∏–Ω–∞: –Ω–µ –Ω–µ—Å—É—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è")
    
    df_train = df_train.drop(cols_to_drop, axis=1)
    df_test = df_test.drop(cols_to_drop, axis=1)
    
    print(f"\n‚úÖ Train: {df_train.shape[1]} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
    print(f"‚úÖ Test:  {df_test.shape[1]} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
    
    # 2. –°–û–ó–î–ê–ù–ò–ï –ù–û–í–´–• –ü–†–ò–ó–ù–ê–ö–û–í
    print("\n" + "=" * 70)
    print("‚ú® 2. –°–û–ó–î–ê–ù–ò–ï –ù–û–í–´–• –ü–†–ò–ó–ù–ê–ö–û–í")
    print("=" * 70)
    
    # 2.1 Age groups
    print("\n2.1 –ì—Ä—É–ø–ø—ã –ø–æ –≤–æ–∑—Ä–∞—Å—Ç—É (Age Groups)")
    
    def create_age_group(age):
        if age < 30:
            return 'young'
        elif age < 50:
            return 'middle'
        else:
            return 'senior'
    
    df_train['age_group'] = df_train['Age'].apply(create_age_group)
    df_test['age_group'] = df_test['Age'].apply(create_age_group)
    
    print("  young:  < 30 –ª–µ—Ç")
    print("  middle: 30-50 –ª–µ—Ç")
    print("  senior: 50+ –ª–µ—Ç")
    print(f"  ‚úÖ –°–æ–∑–¥–∞–Ω –ø—Ä–∏–∑–Ω–∞–∫: age_group")
    
    # 2.2 Zero balance
    print("\n2.2 –ù—É–ª–µ–≤–æ–π –±–∞–ª–∞–Ω—Å (Zero Balance)")
    
    df_train['has_zero_balance'] = (df_train['Balance'] == 0).astype(int)
    df_test['has_zero_balance'] = (df_test['Balance'] == 0).astype(int)
    
    zero_count = df_train['has_zero_balance'].sum()
    zero_pct = (zero_count / len(df_train)) * 100
    print(f"  –ö–ª–∏–µ–Ω—Ç–æ–≤ —Å –Ω—É–ª–µ–≤—ã–º –±–∞–ª–∞–Ω—Å–æ–º: {zero_count:,} ({zero_pct:.1f}%)")
    print(f"  ‚úÖ –°–æ–∑–¥–∞–Ω –ø—Ä–∏–∑–Ω–∞–∫: has_zero_balance")
    
    # 2.3 Balance per product
    print("\n2.3 –ë–∞–ª–∞–Ω—Å –Ω–∞ –ø—Ä–æ–¥—É–∫—Ç (Balance per Product)")
    
    df_train['balance_per_product'] = df_train['Balance'] / (df_train['NumOfProducts'] + 1)
    df_test['balance_per_product'] = df_test['Balance'] / (df_test['NumOfProducts'] + 1)
    
    print(f"  –°—Ä–µ–¥–Ω–∏–π –±–∞–ª–∞–Ω—Å –Ω–∞ –ø—Ä–æ–¥—É–∫—Ç: {df_train['balance_per_product'].mean():,.0f}")
    print(f"  ‚úÖ –°–æ–∑–¥–∞–Ω –ø—Ä–∏–∑–Ω–∞–∫: balance_per_product")
    
    # 2.4 Tenure-Age ratio
    print("\n2.4 –°—Ç–∞–∂ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –≤–æ–∑—Ä–∞—Å—Ç–∞ (Tenure/Age)")
    
    df_train['tenure_age_ratio'] = df_train['Tenure'] / df_train['Age']
    df_test['tenure_age_ratio'] = df_test['Tenure'] / df_test['Age']
    
    print(f"  –°—Ä–µ–¥–Ω–∏–π ratio: {df_train['tenure_age_ratio'].mean():.3f}")
    print(f"  ‚úÖ –°–æ–∑–¥–∞–Ω –ø—Ä–∏–∑–Ω–∞–∫: tenure_age_ratio")
    
    print(f"\n –°–æ–∑–¥–∞–Ω–æ –Ω–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: 4")
    print(f"üìä Train —Ç–µ–ø–µ—Ä—å: {df_train.shape[1]} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")

# 3. –ö–û–î–ò–†–û–í–ê–ù–ò–ï –ö–ê–¢–ï–ì–û–†–ò–ê–õ–¨–ù–´–• –ü–†–ò–ó–ù–ê–ö–û–í
    print("\n" + "=" * 70)
    print("üî§ 3. –ö–û–î–ò–†–û–í–ê–ù–ò–ï –ö–ê–¢–ï–ì–û–†–ò–ê–õ–¨–ù–´–• –ü–†–ò–ó–ù–ê–ö–û–í")
    print("=" * 70)
    
    # 3.1 Geography - One-Hot Encoding
    print("\n3.1 Geography (One-Hot Encoding)")
    
    geography_dummies_train = pd.get_dummies(df_train['Geography'], prefix='Geography', drop_first=True)
    geography_dummies_test = pd.get_dummies(df_test['Geography'], prefix='Geography', drop_first=True)
    
    df_train = pd.concat([df_train, geography_dummies_train], axis=1)
    df_test = pd.concat([df_test, geography_dummies_test], axis=1)
    
    df_train = df_train.drop('Geography', axis=1)
    df_test = df_test.drop('Geography', axis=1)
    
    print(f"  –°–æ–∑–¥–∞–Ω–æ: {', '.join(geography_dummies_train.columns)}")
    print(f"  ‚úÖ Geography –∑–∞–∫–æ–¥–∏—Ä–æ–≤–∞–Ω")
    
    # 3.2 Gender - Label Encoding
    print("\n3.2 Gender (Label Encoding)")
    
    gender_map = {'Female': 0, 'Male': 1}
    df_train['Gender'] = df_train['Gender'].map(gender_map)
    df_test['Gender'] = df_test['Gender'].map(gender_map)
    
    print(f"  Female ‚Üí 0, Male ‚Üí 1")
    print(f"  ‚úÖ Gender –∑–∞–∫–æ–¥–∏—Ä–æ–≤–∞–Ω")
    
    # 3.3 age_group - One-Hot Encoding
    print("\n3.3 age_group (One-Hot Encoding)")
    
    age_group_dummies_train = pd.get_dummies(df_train['age_group'], prefix='age_group', drop_first=True)
    age_group_dummies_test = pd.get_dummies(df_test['age_group'], prefix='age_group', drop_first=True)
    
    df_train = pd.concat([df_train, age_group_dummies_train], axis=1)
    df_test = pd.concat([df_test, age_group_dummies_test], axis=1)
    
    df_train = df_train.drop('age_group', axis=1)
    df_test = df_test.drop('age_group', axis=1)
    
    print(f"  –°–æ–∑–¥–∞–Ω–æ: {', '.join(age_group_dummies_train.columns)}")
    print(f"  ‚úÖ age_group –∑–∞–∫–æ–¥–∏—Ä–æ–≤–∞–Ω")
    
    print(f"\nüìä Train –ø–æ—Å–ª–µ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è: {df_train.shape[1]} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
    print(f"üìä Test –ø–æ—Å–ª–µ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è: {df_test.shape[1]} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")

# 4. –ú–ê–°–®–¢–ê–ë–ò–†–û–í–ê–ù–ò–ï –ß–ò–°–õ–û–í–´–• –ü–†–ò–ó–ù–ê–ö–û–í
    print("\n" + "=" * 70)
    print("‚öñÔ∏è  4. –ú–ê–°–®–¢–ê–ë–ò–†–û–í–ê–ù–ò–ï –ß–ò–°–õ–û–í–´–• –ü–†–ò–ó–ù–ê–ö–û–í")
    print("=" * 70)
    
    # –û—Ç–¥–µ–ª—è–µ–º —Ç–∞—Ä–≥–µ—Ç
    y_train = df_train['Exited'].copy()
    X_train = df_train.drop('Exited', axis=1)
    X_test = df_test.copy()
    
    print(f"\n‚úÖ X_train: {X_train.shape}")
    print(f"‚úÖ y_train: {y_train.shape}")
    print(f"‚úÖ X_test:  {X_test.shape}")
    
    # –ß–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è
    numeric_features = ['CreditScore', 'Age', 'Tenure', 'Balance', 
                       'NumOfProducts', 'EstimatedSalary',
                       'balance_per_product', 'tenure_age_ratio']
    
    print(f"\n–ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º: {', '.join(numeric_features)}")
    
    # StandardScaler
    scaler = StandardScaler()
    X_train[numeric_features] = scaler.fit_transform(X_train[numeric_features])
    X_test[numeric_features] = scaler.transform(X_test[numeric_features])
    
    print(f"‚úÖ –ü—Ä–∏–º–µ–Ω—ë–Ω StandardScaler (mean=0, std=1)")
    
    # 5. –°–û–•–†–ê–ù–ï–ù–ò–ï –û–ë–†–ê–ë–û–¢–ê–ù–ù–´–• –î–ê–ù–ù–´–•
    print("\n" + "=" * 70)
    print("üíæ 5. –°–û–•–†–ê–ù–ï–ù–ò–ï –û–ë–†–ê–ë–û–¢–ê–ù–ù–´–• –î–ê–ù–ù–´–•")
    print("=" * 70)
    
    # –°–æ–∑–¥–∞—ë–º –ø–∞–ø–∫—É
    PROCESSED_DIR.mkdir(parents=True, exist_ok=True)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ
    X_train.to_csv(PROCESSED_DIR / 'X_train.csv', index=False)
    y_train.to_csv(PROCESSED_DIR / 'y_train.csv', index=False)
    X_test.to_csv(PROCESSED_DIR / 'X_test.csv', index=False)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º test_ids –¥–ª—è submission
    test_ids.to_csv(PROCESSED_DIR / 'test_ids.csv', index=False)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º scaler
    with open(PROCESSED_DIR / 'scaler.pkl', 'wb') as f:
        pickle.dump(scaler, f)
    
    print(f"\n‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ:")
    print(f"  ‚Ä¢ X_train.csv:  {X_train.shape}")
    print(f"  ‚Ä¢ y_train.csv:  {y_train.shape}")
    print(f"  ‚Ä¢ X_test.csv:   {X_test.shape}")
    print(f"  ‚Ä¢ test_ids.csv: {len(test_ids)} —Å—Ç—Ä–æ–∫")
    print(f"  ‚Ä¢ scaler.pkl:   StandardScaler –æ–±—ä–µ–∫—Ç")
    
    print(f"\nüìÅ –†–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏–µ: {PROCESSED_DIR}")
    
    # –§–ò–ù–ê–õ
    print("\n" + "=" * 70)
    print("üéâ –≠–¢–ê–ü 5 –ó–ê–í–ï–†–®–Å–ù!")
    print("=" * 70)
    print("\n‚ú® –ß—Ç–æ —Å–¥–µ–ª–∞–Ω–æ:")
    print("  1. –£–¥–∞–ª–µ–Ω—ã: id, CustomerId, Surname")
    print("  2. –°–æ–∑–¥–∞–Ω—ã –Ω–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏: 4")
    print("  3. –ó–∞–∫–æ–¥–∏—Ä–æ–≤–∞–Ω—ã –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ (One-Hot, Label)")
    print("  4. –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω—ã —á–∏—Å–ª–æ–≤—ã–µ (StandardScaler)")
    print("  5. –°–æ—Ö—Ä–∞–Ω–µ–Ω—ã –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ")
    print(f"\nüìä –ò—Ç–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –º–æ–¥–µ–ª–∏: {X_train.shape[1]}")
    print(f"   –ß–∏—Å–ª–æ–≤—ã—Ö: {len(numeric_features)}")
    print(f"   –ë–∏–Ω–∞—Ä–Ω—ã—Ö: {X_train.shape[1] - len(numeric_features)}")
    print("\nüöÄ –°–ª–µ–¥—É—é—â–∏–π —à–∞–≥:")
    print("  cd ../06_modeling")
    print("  python main.py")
    print("\nüí° –¢–∞–º –±—É–¥–µ–º –æ–±—É—á–∞—Ç—å –º–æ–¥–µ–ª–∏ –∏ –¥–µ–ª–∞—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è!")


if __name__ == "__main__":
    main()
