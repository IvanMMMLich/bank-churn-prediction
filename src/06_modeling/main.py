"""
–≠–¢–ê–ü 6: –û–±—É—á–µ–Ω–∏–µ –∏ –æ—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–µ–π
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import pickle

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (accuracy_score, roc_auc_score, f1_score, 
                            confusion_matrix, classification_report, roc_curve)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏
sns.set_style("whitegrid")
plt.rcParams['figure.figsize'] = (12, 6)

# –ü—É—Ç–∏
PROJECT_ROOT = Path(__file__).parent.parent.parent
PROCESSED_DIR = PROJECT_ROOT / 'data' / 'processed'
SUBMISSIONS_DIR = PROJECT_ROOT / 'data' / 'submissions'
RESULTS_DIR = PROJECT_ROOT / 'results'

print("=" * 70)
print("–≠–¢–ê–ü 6: –û–±—É—á–µ–Ω–∏–µ –∏ –æ—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–µ–π")
print("=" * 70)


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —ç—Ç–∞–ø–∞ 6"""
    
    # 1. –ó–ê–ì–†–£–ó–ö–ê –û–ë–†–ê–ë–û–¢–ê–ù–ù–´–• –î–ê–ù–ù–´–•
    print("\n" + "=" * 70)
    print("üìÇ 1. –ó–ê–ì–†–£–ó–ö–ê –û–ë–†–ê–ë–û–¢–ê–ù–ù–´–• –î–ê–ù–ù–´–•")
    print("=" * 70)
    
    X_train_full = pd.read_csv(PROCESSED_DIR / 'X_train.csv')
    y_train_full = pd.read_csv(PROCESSED_DIR / 'y_train.csv').values.ravel()
    X_test = pd.read_csv(PROCESSED_DIR / 'X_test.csv')
    test_ids = pd.read_csv(PROCESSED_DIR / 'test_ids.csv')
    
    print(f"\n‚úÖ X_train: {X_train_full.shape}")
    print(f"‚úÖ y_train: {y_train_full.shape}")
    print(f"‚úÖ X_test:  {X_test.shape}")
    print(f"‚úÖ test_ids: {len(test_ids)}")
    
    print(f"\n–ü—Ä–∏–∑–Ω–∞–∫–∏ ({X_train_full.shape[1]}):")
    print(f"{', '.join(X_train_full.columns.tolist())}")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –±–∞–ª–∞–Ω—Å–∞ –∫–ª–∞—Å—Å–æ–≤
    print(f"\n–ë–∞–ª–∞–Ω—Å –∫–ª–∞—Å—Å–æ–≤:")
    unique, counts = np.unique(y_train_full, return_counts=True)
    for label, count in zip(unique, counts):
        pct = (count / len(y_train_full)) * 100
        print(f"  –ö–ª–∞—Å—Å {label}: {count:,} ({pct:.2f}%)")
    
    # 2. –†–ê–ó–î–ï–õ–ï–ù–ò–ï –ù–ê TRAIN/VALIDATION
    print("\n" + "=" * 70)
    print("‚úÇÔ∏è  2. –†–ê–ó–î–ï–õ–ï–ù–ò–ï –ù–ê TRAIN/VALIDATION")
    print("=" * 70)
    
    X_train, X_val, y_train, y_val = train_test_split(
        X_train_full, y_train_full, 
        test_size=0.2,           # 20% –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏—é
        random_state=42,         # –î–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏
        stratify=y_train_full    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–æ–ø–æ—Ä—Ü–∏—é –∫–ª–∞—Å—Å–æ–≤
    )
    
    print(f"\n‚úÖ Train: {X_train.shape[0]:,} —Å—Ç—Ä–æ–∫ ({X_train.shape[0]/len(X_train_full)*100:.0f}%)")
    print(f"‚úÖ Val:   {X_val.shape[0]:,} —Å—Ç—Ä–æ–∫ ({X_val.shape[0]/len(X_train_full)*100:.0f}%)")
    
    print(f"\n–ë–∞–ª–∞–Ω—Å –≤ Train:")
    unique, counts = np.unique(y_train, return_counts=True)
    for label, count in zip(unique, counts):
        pct = (count / len(y_train)) * 100
        print(f"  –ö–ª–∞—Å—Å {label}: {count:,} ({pct:.2f}%)")

    # 3. –ú–û–î–ï–õ–¨ 1: LOGISTIC REGRESSION (BASELINE)
    print("\n" + "=" * 70)
    print("ü§ñ 3. –ú–û–î–ï–õ–¨ 1: LOGISTIC REGRESSION (Baseline)")
    print("=" * 70)
    
    print("\n–û–±—É—á–∞–µ–º Logistic Regression...")
    
    lr_model = LogisticRegression(
        class_weight='balanced',  # –£—á–∏—Ç—ã–≤–∞–µ–º –¥–∏—Å–±–∞–ª–∞–Ω—Å –∫–ª–∞—Å—Å–æ–≤!
        max_iter=1000,
        random_state=42
    )
    
    lr_model.fit(X_train, y_train)
    print("‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ")
    
    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    y_pred_lr = lr_model.predict(X_val)
    y_pred_proba_lr = lr_model.predict_proba(X_val)[:, 1]
    
    # –ú–µ—Ç—Ä–∏–∫–∏
    print("\nüìä –ú–µ—Ç—Ä–∏–∫–∏ –Ω–∞ Validation:")
    
    accuracy_lr = accuracy_score(y_val, y_pred_lr)
    auc_lr = roc_auc_score(y_val, y_pred_proba_lr)
    f1_lr = f1_score(y_val, y_pred_lr)
    
    print(f"  Accuracy:  {accuracy_lr:.4f} ({accuracy_lr*100:.2f}%)")
    print(f"  AUC-ROC:   {auc_lr:.4f}")
    print(f"  F1-Score:  {f1_lr:.4f}")
    
    # Classification Report
    print("\nüìã Classification Report:")
    print(classification_report(y_val, y_pred_lr, target_names=['–û—Å—Ç–∞–ª–∏—Å—å', '–£—à–ª–∏']))
    
    # 4. –ú–û–î–ï–õ–¨ 2: RANDOM FOREST (–ú–û–©–ù–ê–Ø)
    print("\n" + "=" * 70)
    print("üå≥ 4. –ú–û–î–ï–õ–¨ 2: RANDOM FOREST")
    print("=" * 70)
    
    print("\n–û–±—É—á–∞–µ–º Random Forest...")
    print("(–º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å 1-2 –º–∏–Ω—É—Ç—ã)")
    
    rf_model = RandomForestClassifier(
        n_estimators=100,         # 100 –¥–µ—Ä–µ–≤—å–µ–≤
        max_depth=10,             # –ì–ª—É–±–∏–Ω–∞ –¥–µ—Ä–µ–≤—å–µ–≤
        min_samples_split=20,     # –ú–∏–Ω–∏–º—É–º –¥–ª—è —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è
        min_samples_leaf=10,      # –ú–∏–Ω–∏–º—É–º –≤ –ª–∏—Å—Ç–µ
        class_weight='balanced',  # –£—á–∏—Ç—ã–≤–∞–µ–º –¥–∏—Å–±–∞–ª–∞–Ω—Å!
        random_state=42,
        n_jobs=-1                 # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å–µ —è–¥—Ä–∞ CPU
    )
    
    rf_model.fit(X_train, y_train)
    print("‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ")
    
    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    y_pred_rf = rf_model.predict(X_val)
    y_pred_proba_rf = rf_model.predict_proba(X_val)[:, 1]
    
    # –ú–µ—Ç—Ä–∏–∫–∏
    print("\nüìä –ú–µ—Ç—Ä–∏–∫–∏ –Ω–∞ Validation:")
    
    accuracy_rf = accuracy_score(y_val, y_pred_rf)
    auc_rf = roc_auc_score(y_val, y_pred_proba_rf)
    f1_rf = f1_score(y_val, y_pred_rf)
    
    print(f"  Accuracy:  {accuracy_rf:.4f} ({accuracy_rf*100:.2f}%)")
    print(f"  AUC-ROC:   {auc_rf:.4f}")
    print(f"  F1-Score:  {f1_rf:.4f}")
    
    # Classification Report
    print("\nüìã Classification Report:")
    print(classification_report(y_val, y_pred_rf, target_names=['–û—Å—Ç–∞–ª–∏—Å—å', '–£—à–ª–∏']))

# 5. –°–†–ê–í–ù–ï–ù–ò–ï –ú–û–î–ï–õ–ï–ô
    print("\n" + "=" * 70)
    print("‚öñÔ∏è  5. –°–†–ê–í–ù–ï–ù–ò–ï –ú–û–î–ï–õ–ï–ô")
    print("=" * 70)
    
    comparison = pd.DataFrame({
        '–ú–æ–¥–µ–ª—å': ['Logistic Regression', 'Random Forest'],
        'Accuracy': [accuracy_lr, accuracy_rf],
        'AUC-ROC': [auc_lr, auc_rf],
        'F1-Score': [f1_lr, f1_rf]
    })
    
    print("\nüìä –°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞:\n")
    print(comparison.to_string(index=False))
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å
    best_model_name = 'Random Forest' if auc_rf > auc_lr else 'Logistic Regression'
    best_model = rf_model if auc_rf > auc_lr else lr_model
    best_auc = max(auc_rf, auc_lr)
    
    print(f"\nüèÜ –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å: {best_model_name} (AUC-ROC: {best_auc:.4f})")
    
    # 6. –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø: ROC-CURVE
    print("\n" + "=" * 70)
    print("üìà 6. ROC-–ö–†–ò–í–ê–Ø")
    print("=" * 70)
    
    fig, ax = plt.subplots(figsize=(10, 8))
    
    # ROC –¥–ª—è Logistic Regression
    fpr_lr, tpr_lr, _ = roc_curve(y_val, y_pred_proba_lr)
    ax.plot(fpr_lr, tpr_lr, label=f'Logistic Regression (AUC = {auc_lr:.3f})', linewidth=2)
    
    # ROC –¥–ª—è Random Forest
    fpr_rf, tpr_rf, _ = roc_curve(y_val, y_pred_proba_rf)
    ax.plot(fpr_rf, tpr_rf, label=f'Random Forest (AUC = {auc_rf:.3f})', linewidth=2)
    
    # –î–∏–∞–≥–æ–Ω–∞–ª—å (—Å–ª—É—á–∞–π–Ω–∞—è –º–æ–¥–µ–ª—å)
    ax.plot([0, 1], [0, 1], 'k--', label='Random (AUC = 0.500)', linewidth=1)
    
    ax.set_xlabel('False Positive Rate', fontsize=12)
    ax.set_ylabel('True Positive Rate', fontsize=12)
    ax.set_title('ROC Curve - –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π', fontsize=14, fontweight='bold')
    ax.legend(loc='lower right', fontsize=11)
    ax.grid(True, alpha=0.3)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º
    figures_dir = RESULTS_DIR / 'figures'
    output_path = figures_dir / '06_roc_curve.png'
    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    print(f"‚úÖ ROC-–∫—Ä–∏–≤–∞—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {output_path}")
    
    plt.show()
    
    # 7. FEATURE IMPORTANCE (–¥–ª—è Random Forest)
    print("\n" + "=" * 70)
    print("üîç 7. –í–ê–ñ–ù–û–°–¢–¨ –ü–†–ò–ó–ù–ê–ö–û–í (Random Forest)")
    print("=" * 70)
    
    feature_importance = pd.DataFrame({
        'Feature': X_train.columns,
        'Importance': rf_model.feature_importances_
    }).sort_values('Importance', ascending=False)
    
    print("\nüìä –¢–æ–ø-10 –≤–∞–∂–Ω–µ–π—à–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:\n")
    for i, row in feature_importance.head(10).iterrows():
        print(f"  {row['Feature']:25s}: {row['Importance']:.4f}")
    
    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
    fig, ax = plt.subplots(figsize=(10, 8))
    
    top10 = feature_importance.head(10)
    ax.barh(top10['Feature'], top10['Importance'], color='steelblue', edgecolor='black', alpha=0.7)
    ax.set_xlabel('–í–∞–∂–Ω–æ—Å—Ç—å', fontsize=12)
    ax.set_title('–¢–æ–ø-10 –≤–∞–∂–Ω–µ–π—à–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (Random Forest)', fontsize=14, fontweight='bold')
    ax.invert_yaxis()
    ax.grid(True, alpha=0.3, axis='x')
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º
    output_path = figures_dir / '06_feature_importance.png'
    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    print(f"\n‚úÖ –ì—Ä–∞—Ñ–∏–∫ —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {output_path}")
    
    plt.show()
    
    # 8. –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–Ø –ù–ê TEST –ò –°–û–ó–î–ê–ù–ò–ï SUBMISSION
    print("\n" + "=" * 70)
    print("üéØ 8. –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–Ø –ù–ê TEST –ò –°–û–ó–î–ê–ù–ò–ï SUBMISSION")
    print("=" * 70)
    
    print(f"\n–ò—Å–ø–æ–ª—å–∑—É–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å: {best_model_name}")
    
    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ test
    y_test_pred = best_model.predict(X_test)
    
    print(f"‚úÖ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å–¥–µ–ª–∞–Ω—ã –¥–ª—è {len(y_test_pred):,} –∫–ª–∏–µ–Ω—Ç–æ–≤")
    
    # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
    unique, counts = np.unique(y_test_pred, return_counts=True)
    print(f"\n–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π:")
    for label, count in zip(unique, counts):
        pct = (count / len(y_test_pred)) * 100
        print(f"  –ö–ª–∞—Å—Å {label}: {count:,} ({pct:.2f}%)")
    
    # –°–æ–∑–¥–∞–Ω–∏–µ submission —Ñ–∞–π–ª–∞
    submission = pd.DataFrame({
        'id': test_ids['id'],
        'Exited': y_test_pred
    })
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
    SUBMISSIONS_DIR.mkdir(parents=True, exist_ok=True)
    submission_path = SUBMISSIONS_DIR / 'submission.csv'
    submission.to_csv(submission_path, index=False)
    
    print(f"\n‚úÖ Submission —Ñ–∞–π–ª —Å–æ–∑–¥–∞–Ω: {submission_path}")
    print(f"   –°—Ç—Ä–æ–∫: {len(submission):,}")
    print(f"   –°—Ç–æ–ª–±—Ü—ã: id, Exited")
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
    models_dir = RESULTS_DIR / 'models'
    models_dir.mkdir(parents=True, exist_ok=True)
    
    model_filename = 'random_forest.pkl' if best_model_name == 'Random Forest' else 'logistic_regression.pkl'
    model_path = models_dir / model_filename
    
    with open(model_path, 'wb') as f:
        pickle.dump(best_model, f)
    
    print(f"‚úÖ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {model_path}")
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
    tables_dir = RESULTS_DIR / 'tables'
    comparison.to_csv(tables_dir / '06_model_comparison.csv', index=False)
    feature_importance.to_csv(tables_dir / '06_feature_importance.csv', index=False)
    
    # –§–ò–ù–ê–õ
    print("\n" + "=" * 70)
    print("–≠–¢–ê–ü 6 –ó–ê–í–ï–†–®–Å–ù! –ü–†–û–ï–ö–¢ –ì–û–¢–û–í! ")
    print("=" * 70)
    print(f"\nüèÜ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
    print(f"  ‚Ä¢ –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å: {best_model_name}")
    print(f"  ‚Ä¢ Accuracy:  {accuracy_rf if best_model_name == 'Random Forest' else accuracy_lr:.2%}")
    print(f"  ‚Ä¢ AUC-ROC:   {best_auc:.4f}")
    print(f"  ‚Ä¢ F1-Score:  {f1_rf if best_model_name == 'Random Forest' else f1_lr:.4f}")
    print(f"\nüìÅ –§–∞–π–ª—ã —Å–æ–∑–¥–∞–Ω—ã:")
    print(f"  ‚Ä¢ Submission: {submission_path}")
    print(f"  ‚Ä¢ –ú–æ–¥–µ–ª—å: {model_path}")
    print(f"  ‚Ä¢ –ì—Ä–∞—Ñ–∏–∫–∏: results/figures/06_*.png")
    print(f"  ‚Ä¢ –¢–∞–±–ª–∏—Ü—ã: results/tables/06_*.csv")


if __name__ == "__main__":
    main()

